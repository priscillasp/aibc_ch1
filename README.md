# aibc_ch1

# **Wysa: Digital Mental Health StartUp - Case Study**

## Company Information

Wysa Inc. is a mental health startup that offers an AI-powered chatbot designed to provide emotional support and mental health resources to users. The Wysa AI Coach is promoted as an 'emotionally intelligent' service which uses cognitive-behavioral technique (CBT), DBT, meditation, breathing, yoga, motivational interviewing and micro-actions to help users feel better and build mental resilience. Wysa has evolved into a platform that not only serves individual users but also offers solutions for employers and healthcare providers, aiming to fill the significant gap in mental health services with an accessible, cost-effective, and clinically validated tool <a href="#ref1">[1]</a>. 
Wysa Inc. was founded in 2015 by Jo Arrarwal and Ramakant Vempati. Headquarters are in Bengaluru, India. However, they offer services around the world under the name Wysa Ltd, a private limited company, registered in the UK and Wysa Inc., a private company registered in the USA <a href="#ref1">[9]</a>. Jo Aggarwal, co-founder, said she was inspired to create Wysa out of her own experience with depression <a href="#ref1">[11]</a>. The idea for AI-driven solutions emerged from their ambition to address the global mental health demand by providing widespread and immediate access to their ‘emotionally intelligent’ Wysa AI Coach.
Wysa is funded by 13 investors according to Crunchbase <a href="#ref1">[2]</a>. The lead investors are DigitalHealth.London Accelerator, Health Quad (based in Dehli, India), Zurich Insurance Group and W Health Ventures (based in Boston, USA). Wysa has raised a total of $29.5M in funding over 7 funding rounds. Previous backers have included both Amazon and Google who invested through their digital assistant funds <a href="#ref1">[3]</a>. Funding comes from a combination of grants and series A/B funding from venture capitalists. 

## Business Activities

Wysa attempts to tackle the issue of lack of accessibility to mental health support by providing an AI-powered chatbot that specializes in therapeautic technique to provide emotional support, coping strategies, and mental health resources through smartphones or other devices. Wysa has also conducted several studies with employees in USA and UK to understand and destigmatize problems around employee mental health. Their studies found that as many as 4 in 10 employees suffer from symptoms of depression or anxiety and about 80% of the workers said they would rather pretend to be sick than tell their bosses how stressed and anxious they are <a href="#ref1">[14]</a>. To provide a solution for this issue Wysa offers a program called, "Wysa For Employers." It's a program companies can sign up for to provide their employees with Wysa’s Self-Care premium app. Employers who sign up also receive access to analytics and insights, co-branded content, and a mental health calendar to help plan interactive campaigns <a href="#ref1">[1]</a>. 
Wysa's target customer is someone who is experiencing mild symptoms of low mood, stress or anxiety. The intended customer could fall under a wide range of demographics as their app is used by individuals from more than 95 countries across the world from many age groups. Interestingly, Wysa is not designed to assist users going through a crises or struggling with severe mental health conditions <a href="#ref1">[13]</a>. In any of these cases, Wysa can only suggest that users seek advanced and professional medical help. 
As for the market size of this set of customers, it's challenging to provide precise numbers due to the diverse nature and global reach of mental health issues. However, the market for mental health tech solutions has been growing rapidly in recent years, according to Grand View Research:
> "The digital mental health market size was valued at $7.5 billion in 2024 <a href="#ref1">[7]</a>,  and it is predicted to expand at a compound annual growth rate (CAGR) of 16.9% towards USD 23.8 billion by 2032 <a href="#ref1">[8]</a>."

Wysa's unfair advantage over its competitors lies in its blend of AI-driven conversation with evidence-based cognitive-behavioral techniques (CBT), anonymous mental health support, and its status as an FDA approved Breakthrough Device Designation. This unique combination allows for easily accessible and anonymous engagement in a safe space for users to discuss their mental health. This provides a major advantage to their niche of employees, some of whom do not want to admit to others that they are struggling mentally. Wysa is also the only digital mental health solution with an AI chatbot that recieved an FDA Breakthrough Device Designation, indicating a high level of clinical validation for its technology <a href="#ref1">[15]</a>. Lastly, Wysa's advantage also lies in their global market presence and their focus on a broad range of languages. 

### **Technology**
+ ***Anonymous interaction with AI chatbot***: Wysa uses algorithms that irreversibly redact any inadvertent personal identifiers entered in English. They perform Data Protection Impact Assessment (DPIA) for personal data processing. They use TLS and SSL encryption during transfer and AES-256 protocol at rest. Random identifiers are used for all data transactions between AI Coach and their servers. Their systems are secured with role-based access, strong passwords and two-step verification. They perform regular penetration tests of our Apps and Infrastructure. Wysa meets standards of the NHS Digital Data Security and Protection Toolkit (DSP Toolkit). Wysa mobile App is registered with UK MHRA as a CE/UKCA Class I medical device. Wysa's Information Security Management System (ISMS) and Privacy Information Management System (PIMS) is certified for ISO 27001:2013 and 27701: 2019 <a href="#ref1">[9]</a>.
+ ***AI Wysa Coach***: They use proprietary Artificial Intelligence and Natural Language Processing/Understanding (NLP/NLU) algorithms to understand user messages. All the AI programs used in their Apps are “FIXED” or “CLOSED”, and all chatbot responses to the user are created with clinical input and subjected to detailed safety testing before being deployed. Wysa owns the Intellectual Property and rights to these AI generated content scripts. These scripts are rigorously quality checked for copyright and plagiarism, clinically validated using a therapist-in-the-loop for safety, privacy, quality and performance. Only validated content gets released. The algorithms run at conversational nodes within a decision-tree structure <a href="#ref1">[9]</a>. The primary purpose of the AI-based processing is to detect and retain limited context from user messages to personalize and provide empathetic conversations and to detect at-risk situations, such as any SOS, self-harm and abuse triggers, so as to signpost users to clinically validated supportive resources and helplines.

## Landscape and Trends 

Wysa Inc. is in the Digital Mental Health field. However, in this field the integration of artificial intelligence technology has moved slower than in other fields such as business, tech, etc., due to ethical concerns. The APA, American Psychological Association, has one article on AI innovations and expresses great concerns over inclusivity, consent, patient privacy and misinformation given to a mentally vulnerable population <a href="#ref1">[4]</a>. Although there are less technological advancements in this field, there is a small pool of innovative technology that has been effective in helping clients and clinicians alike. An example, is a natural language processing tool used by a company called Eleos which built AI technology for providers to spend less time on administrative tasks and more on patient care. This tool is used to listen to sessions, take notes, and highlight themes and risks for practitioners to review and has automations including analysis of assessments, tracking of patient symptoms, and practice management <a href="#ref1">[4]</a>. Additionally, preliminary research has been done to use natural language models to assess therapy effectiveness. The researchers gave their large language model a dataset including thousands of hours of therapy sessions and the output was to identify missed opportunities to validate a patient or failures to ask key questions, such as whether a suicidal patient has a firearm at home <a href="#ref1">[5]</a>. The researchers concluded that analyzing therapist language at scale using NLP is feasible but no further action has been taken to implement this tool since the paper was published in late 2022. Also, it is worth mentioning that there are other AI tools used in other branches of mental health, including research in psychiatric and neuroscientific fields. However, I focused on how AI is being used in the psychologist to patient interaction for this case study. Specifically in the context of an AI chatbot used to give therapeutic support to those in need the biggest players are Wysa and the Woebot. Other companies using AI chatbots as a supportive and emotionally welcoming friend is Replika, designed for emotional companionship and self-discovery; and Tess by X2 AI, which provides psychological support and personalizes conversations based on the user's needs. These last two platforms use more of a relationship based interaction with the chatbot to provide a safe space as a "friend to lean on in times of need.” On the other hand, Wysa and Woebot were developed to provide clinically tested therapeutic approaches like CBT or DBT. Both apps are based on CBT techniques and also promote the notion of self-care with the AI chatbots working like mini-life coaches. Both apps collaborate closely with psychologists who validate the AI chatbots' responses and continually monitor user interactions to ensure the support provided is safe and of the highest quality.

## Results
Wysa is a global leader in AI-driven mental health support, available both to individuals and employees, through employer benefits programs and healthcare services. Wysa’s customers include Accenture Global, Aetna International, NHS, Cincinnati Children’s Hospital Medical Center, and the Ministry of Health in Singapore. Wysa has held over half a billion AI chat conversations with more than five million people about their mental health across 95 countries <a href="#ref1">[1]</a>. The Wysa app has a 4.9-star rating from 20.2K reviews on the Apple App Store and 4.7 star rating from 144K reviews on the Google Play Store.
Companies in the digital mental health space often measure success through: user engagement metrics, clinical effectiveness, user satisfaction scores, conversation or session length, user retention and clinical trial outcomes. Wysa is frequently publishing new clinical evidence in behavioural health, with peer-reviewed trials and efficacy studies across a range of clinical concerns, geographies and age groups to understand the effectiveness of their AI chatbot. According to their website, Over 91% employees rated Wysa as 'helpful' with an average rating of 4.2 out of 5. They also claimed a 33% reduction in lost-time days and 10x access to mental health support. One of their studies looked at the AI chatbot effectiveness in users with symptoms of depression. The sample size was quite small, the results showed an improvement in mood between the groups (ie, high vs low users of AI bot; n=108 and n=21, respectively) revealed that the high users group had significantly higher average improvement (mean 5.84 [SD 6.66]) compared with the low users group (mean 3.52 [SD 6.15]). Moreover, 67.7% of those user-provided feedback responses found the app experience helpful and encouraging <a href="#ref1">[12]</a>. 
One of Wysa’s most prominent competitors is Woebot. Woebot was launched in 2017, and has a similar mission as Wysa to make mental health radically accessible to people worldwide. Since its launch, Woebot has been used by a wide age range of users in more than 130 countries​​. Woebot, however, is a service specifically targeted to adolescents, adults and clinicians they help collect patient reported outcomes. On the other hand, Wysa also targets its services for employers. Woebot has acumulated almost 5x the funding Wysa has with a whopping $123.3 million in total funding from venture capitalist. Woebot has conducted 15 radomized control trials (RCTs) whereas Wysa has complete 7 RCTs. Woebot claims that 91 % of users reported being satisfied with Woebot which is about the same as user satisfaction reported for Wysa. Woebot has spoken to 1.5 million users whereas Wysa chatbot has spoken to 5 million people <a href="#ref1">[10]</a>. Although Woebot has received much more funding it seems that both companies are parallel in their global reach, growth and product effectiveness.  

## Recommendations 
If I were to be an advisor for Wysa Inc. I would recommend they create a more effective and empathetic version of their AI chatbot. I would suggest this because many of the negative reviews on Apple and Google app stores stemmed from how cold and generic the chatbot responses were. Users mentioned that it doesn’t respond directly to your written answers and only works well when the user selects a pre-populated responses. Even those users who positively reviewed the app mentioned that the chatbot doesn’t seem to really understand what they’re asking or saying <a href="#ref1">[11]</a>. Additionally, another user wrote an article about his experience with the Wysa app found the bot to be condescending at times. The AI bot coach would repeatedly call him “buddy.” Which in the cultural context of the US where a term like buddy can be used in a derogatory way, this is not how a therapist should respond to a client <a href="#ref1">[6]</a>. 
From my research theres seems to be a disconnect between how Wysa executives *think* the chatbot is working versus how users say the chatbot is *actually* working. According to their website Wysa claims the purpose of the technology behind their AI bot is to “personalize and provide empathetic and safe conversation.” However, based on user reviews their product is not effectively doing that. Furthermore, in their latest studies on how interacting with the chatbot affected a depressed population only 67% reported any difference in how they felt <a href="#ref1">[12]</a>.
To more closely simulate a therapist to client conversation I would suggest the company create a generative and adaptive AI model. I would create a chatbot system that uses a generative model to generate responses based on pre-existing psychological knowledge and therapeatic approaches, but also incorporates adaptive learning mechanisms to improve its responses over time to be tailored to the client. Wysa does already use AI generated content that is then reviewed by a psychologist for safety and quality assurance. Instead, my approach would be to train the AI to have limits on what the chatbot can and cannot. During the creation of the AI bot we would use a dataset with hours of therapy session transcripts that the program must read and understand to then be trained to approach client interactions with a similar tone and style. In closely simulating a conversation with a psychologist the flow should be adaptive based on what time user needs at that time. This adaptive model would eliminate the user reported problem of the chatbot "not really understanding what they say." To control those adaptive responses from the AI bot for safety and quality assurance there would be a strict “rulebook” of what the chatbot can not say. So instead of the therapist hand selecting each response as Wysa does currently, instead there would be a set of conditions that the Ai bot must adhere to. Similar to ChatGPT which has a similar structure that does not allow for any conversations around violent, sexual or illegal content. I believe the implementation of a generative and adaptive AI chatbot would not only help the company address negative feedback but would also help Wysa accomplish their mission of effectively helping users overcome mental difficulties at a widely accessible scale. 

## References 
<a id="ref1"></a>[1]: [Wysa Website](https://www.wysa.com/)
<a id="ref1"></a>[2]: [Crunchbase Financial Info](https://www.crunchbase.com/organization/touchkin-eservices)
<a id="ref1"></a>[3]: [Techcrunch Financial Info](https://techcrunch.com/2022/07/14/wysa-20-million-series-b-funding-expand-therapist-chatbot-wider-mental-health-services/)
<a id="ref1"></a>[4]: [APA on AI Implementation](https://www.apa.org/monitor/2023/07/psychology-embracing-ai)
<a id="ref1"></a>[5]: [NLP to measure effective therapy research](https://www.nature.com/articles/s44184-022-00020-9)
<a id="ref1"></a>[6]: [Wysa app Review](https://josephctylerwords.medium.com/review-wysa-54b127bb12a3)
<a id="ref1"></a>[7]: [Grand View Research - Landscape](https://www.grandviewresearch.com/industry-analysis/mental-health-apps-market-report)
<a id="ref1"></a>[8]: [Grand View Research - Landscape more info](https://www.linkedin.com/pulse/mental-health-apps-market-grand-view-research-j24lf/?trk=article-ssr-frontend-pulse_more-articles_related-content-card)
<a id="ref1"></a>[9]: [Wysa Terms of Service](https://legal.wysa.io/terms)
<a id="ref1"></a>[10]:[Woebot Website](https://woebothealth.com/)
<a id="ref1"></a>[11]:[Wysa App Review 2](https://www.choosingtherapy.com/wysa-app-review/#:~:text=Wysa%20was%20founded%20in%202016,around%20seeking%20help%20and%20support.)
<a id="ref1"></a>[12]: [Wysa Chatbot Depression Study](https://mhealth.jmir.org/2018/11/e12106/)
<a id="ref1"></a>[13]: [Wysa FAQ](https://www.wysa.com/faq)
<a id="ref1"></a>[14]: [Wysa Research on Employees](https://www.wysa.com/all-worked-up)
<a id="ref1"></a>[15]: [Wysa FDA Approval](https://www.businesswire.com/news/home/20220512005084/en/Wysa-Receives-FDA-Breakthrough-Device-Designation-for-AI-led-Mental-Health-Conversational-Agent)
